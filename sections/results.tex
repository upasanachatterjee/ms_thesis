\section{Discussion}
Our continued pre-training experiments reveal complex interactions between triplet-based contrastive learning and metalinguistic auxiliary objectives that depend critically on both training configuration and dataset composition. On the subset dataset (1.6M articles with complete GDELT coverage), metalinguistic features consistently improved performance, with particularly strong gains for center and right class classification. The full \textsc{BigNewsBLN} corpus (4.5M articles, 35\% with GDELT metadata) exhibited contrasting behavior: single-triplet configurations performed substantially worse when metalinguistic objectives were added ($T_{id}(1)$: 56.98 vs. $T_{id}(1) + T_h$: 51.40), likely due to noisy gradients from sparse GDELT coverage. However, at higher triplet counts, the theme prediction objective yielded substantial improvements: $T_{id}(16) + T_h$ achieved 60.55 F1-Macro (+7.67 over triplet-only), and $T_{id}(32) + T_h$ reached 62.19 F1-Macro (+2.04 over triplet-only), indicating that metalinguistic objectives provide the most value when paired with sufficient triplet samples to establish robust primary gradients.

Performance across training epochs exhibited unexpected variability that warrants further investigation, with best results sometimes occurring at epoch 1 rather than epoch 2 for both the subset and full dataset investigations. This suggests that factors such as random triplet sampling may significantly influence convergence dynamics. The full dataset showed even greater epoch-to-epoch variation than the subset, likely exacerbated by noise from articles lacking GDELT metadata. Despite this variability, the consistent improvements with metalinguistic objectives provide strong evidence that they capture valuable complementary signals for political ideology detection. Theme prediction appears particularly effective, likely because topical focus (e.g., emphasis on immigration, healthcare, or economic policy) correlates with ideological framing in ways that pure contrastive learning cannot fully capture. Tone regression showed more modest gains, suggesting that sentiment signals may be less consistently ideologically aligned in political news discourse. Joint training on both tone and theme objectives occasionally outperformed single-feature approaches, suggesting that these metalinguistic dimensions capture complementary aspects of ideological expression that together provide richer gradient signals than either objective alone.

\subsection{Domain-adapted Models vs. Large Language Models}

Our experimental results reveal distinct performance profiles between transformer-based and LLM-based approaches. On the Media split, our best domain-adapted transformer ($T_{id}(32) + T_h$) achieved 62.19 F1-Macro through continued pre-training with metalinguistic objectives, while zero-shot GPT-4o-mini reached only 51.86 F1-Macro. Fine-tuning GPT-4o-mini with 2000 samples improved performance to 69.37 F1-Macro, surpassing our specialized transformer. However, this introduced uncertainty about source leakage in the LLM's opaque pre-training corpus that do not apply to our transformer pre-training.

Despite these quantitative differences, neither approach achieves ideal performance, particularly on right and center classifications. This asymmetry poses significant deployment risks: systematically biased classifiers that mischaracterize centrist and right-leaning content could reinforce rather than mitigate information polarization. The consistent performance gains from metalinguistic objectives, particularly for center and right classes, provide empirical evidence that affective and stylistic dimensions contain discriminative signals not fully captured by content-based approaches alone. This aligns with theoretical work emphasizing the role of linguistic framing and emotional tone in ideological expression \citep{hamborg2019automatedmediabias,rashkin2016connotationframesdatadriveninvestigation}.

The optimal approach depends on deployment constraints and risk tolerance. Specialized transformers with metalinguistic objectives offer strong performance with moderate computational requirements, full model transparency, and better data efficiency, which makes them suitable for scenarios where interpretability and trust are critical. Fine-tuned LLMs can achieve superior raw performance when substantial labelled data and computational resources are available, though practitioners must weigh this against potential data contamination, higher operational costs, and reduced explainability \citep{Wen_2023}.