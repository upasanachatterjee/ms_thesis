\chapter{Discussion and Analysis}
\label{ch:discussion}

This chapter provides an analysis of our experimental findings from both the metalinguistic feature integration framework (Chapter~\ref{sec:continued-pretraining}) and the large language model fine-tuning investigation (Chapter~\ref{sec:llm-finetuning}). We examine the theoretical implications, practical trade-offs, and methodological insights emerging from our comparative evaluation of specialized transformer architectures versus general-purpose LLMs for political bias classification. Our discussion synthesizes empirical observations with broader considerations of computational efficiency, interpretability, and deployment viability in real-world systems.

\input{sections/8_discussion/metalinguistic_analysis.tex}
\input{sections/8_discussion/comparative_analysis.tex}
