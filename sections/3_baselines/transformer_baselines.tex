\section{Fine-tuned Transformer Architectures}
\label{sec:transformer-baselines}

Our transformer baseline evaluation encompasses both general-purpose pre-trained language models and domain-adapted architectures specifically designed for political text analysis. This comparison enables assessment of the value of domain-specific adaptation for political bias detection.

\subsection{General-Purpose Transformer Models}

We evaluated three representative pre-trained transformer architectures: BERT \citep{devlin2019bert}, RoBERTa \citep{liu2019roberta}, and BART \citep{lewis2020bart}. Each model was fine-tuned end-to-end for three-class political bias classification by adding a linear classification head to the pre-trained encoder representations.

All models employed identical training procedures to ensure fair comparison. Fine-tuning utilized the AdamW optimizer with learning rate scheduling and early stopping based on validation set performance. Complete hyperparameter configurations and training details are provided in Table~\ref{tab:finetuning_config} in the appendices.

\subsection{Domain-Adapted Architecture: POLITICS Model}

We include the current state-of-the-art system for article-level political bias classification, the POLITICS model developed by \citet{liu2022politics}. This system represents a RoBERTa-based encoder enhanced through continued pre-training with carefully designed contrastive learning objectives.

The POLITICS model addresses source leakage through a triplet-loss framework that encourages the learning of ideology-specific rather than source-specific representations. The training procedure employs $\langle$anchor, positive, negative$\rangle$ triplets where:

\begin{itemize}
    \item \textbf{Anchor}: Article $a$ with political label $l \in \{\text{left}, \text{center}, \text{right}\}$
    \item \textbf{Positive}: Article $p$ with identical label $l$ from a different publication source
    \item \textbf{Negative}: Article $n$ with different label $m \neq l$ from any source
\end{itemize}

The triplet loss objective encourages the model to produce representations where ideologically similar articles from different sources are closer in embedding space than ideologically different articles:

\begin{equation}
    \mathcal{L}_{\text{triplet}} = \sum_{\langle a,p,n \rangle \in \mathcal{T}} \max\left( \|f(a) - f(p)\|_2 - \|f(a) - f(n)\|_2 + \delta, 0\right)
    \label{eqn:triplet_loss}
\end{equation}

where $f(\cdot)$ denotes the model's [CLS] token representation, and $\delta$ is a margin hyperparameter. The POLITICS model incorporates both story-level objectives (positive samples discuss the same event) and ideology-level objectives (positive samples share political orientation) during continued pre-training.
