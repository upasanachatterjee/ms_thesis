\section{Methodology and Architecture}
\label{sec:methodology}

Our technical approach builds upon the RoBERTa transformer architecture enhanced through continued pre-training with multiple supervised objectives. 
\subsection{Metalinguistic Feature Sources}
\label{sec:feature-sources}

To obtain large-scale metalinguistic annotations without prohibitive manual labeling costs, we leverage the Global Database of Events, Language, and Tone (GDELT) Project,\footnote{\url{https://www.gdelt.org/}} a comprehensive news monitoring system that processes articles across 100+ languages and extracts structured metadata through automated NLP pipelines. Following \citet{ronnback2025biasoutlets}, who demonstrate the effectiveness of GDELT-derived features for source-level ideology detection, we integrate two complementary metadata streams:

\begin{description}
    \item[\textsc{V2Themes}:] Multi-label topic annotations generated through lexicon-based keyword matching against a curated taxonomy of 2,300+ categories (e.g., \texttt{ENV\_CLIMATECHANGE}, \texttt{ECON\_INFLATION}). Each article receives multiple theme codes reflecting its topical composition, enabling models to learn associations between ideological orientation and topic selection patterns.
    
    \item[\textsc{V2Tone}:] Sentiment polarity scores computed as the mean valence of matched lexical items, yielding continuous values typically in the range $[-10, +10]$. While GDELT provides six tonal subdimensions (overall tone, positive/negative scores, polarity, activity reference density, and self-reference density), we employ only the aggregate tone score to maintain computational efficiency.
\end{description}

These features capture complementary aspects of political discourse: thematic annotations reflect editorial choices about which topics receive coverage and emphasis, while tonal measurements quantify the emotional framing and sentiment orientation of the presentation.

Our pre-training dataset consists of articles from the \textsc{BigNewsBLN} dataset \citep{liu2022politics} for which GDELT metadata is available. This subset comprises approximately 1.6 million articles containing both \textsc{V2Themes} and \textsc{V2Tone} annotations, or around 35\% of the total \textsc{BigNewsBLN} dataset. This extended dataset is available 
\href{https://huggingface.co/datasets/dragonslayer631/bignewsalign-with-gdelt}{on HuggingFace} 
.\footnote{The data is available under the CC-BY-SA 4.0 license, same as the original dataset \citep{liu2022politics}.}

\subsection{Multi-Task Learning Framework}
\label{sec:multitask-framework}

We implement a unified multi-task learning architecture that optimizes three concurrent objectives during continued pre-training:

\begin{align}
\mathcal{L}_{total} &=  \mathcal{L}_{ideology} + \mathcal{L}_{themes} + \mathcal{L}_{tone} \label{eq:total-loss}
\end{align}

The three component losses are:

\begin{description}
    \item[\textbf{Ideological Representation Loss} ($\mathcal{L}_{ideology}$):] A triplet-loss objective similar to the POLITICS model (see Section~\ref{sec:transformer-baselines}) that learns to position articles from ideologically similar sources closer in the representation space:
    
    \begin{equation}
    \mathcal{L}_{ideology} = \max(0, \delta + d(a, p) - d(a, n)) \label{eq:triplet-loss}
    \end{equation}
    
    where $a$ is the anchor article, $p$ is a positive example from the same ideological orientation, $n$ is a negative example from a different orientation, $d(\cdot, \cdot)$ is cosine distance, and $\delta$ is the margin parameter.
    
    \item[\textbf{Thematic Classification Loss} ($\mathcal{L}_{themes}$):] Multi-label binary cross-entropy for predicting GDELT theme annotations, enabling the model to learn associations between ideological positions and topic coverage patterns:
    
    \begin{equation}
    \mathcal{L}_{themes} = -\frac{1}{K} \sum_{k=1}^{K} \left[ y_k \log(\hat{y}_k) + (1-y_k) \log(1-\hat{y}_k) \right] \label{eq:theme-loss}
    \end{equation}
    
    where $K$ is the number of theme categories, $y_k$ is the binary ground truth for theme $k$, and $\hat{y}_k$ is the predicted probability.
    
    \item[\textbf{Tonal Regression Loss} ($\mathcal{L}_{tone}$):] Mean squared error for predicting GDELT sentiment scores, allowing the model to capture emotional framing patterns:
    
    \begin{equation}
    \mathcal{L}_{tone} = \frac{1}{N} \sum_{i=1}^{N} (s_i - \hat{s}_i)^2 \label{eq:tone-loss}
    \end{equation}
    
    where $s_i$ is the true tone score and $\hat{s}_i$ is the predicted score for article $i$.
\end{description}

This multi-task approach follows the principle that shared representations beneficial for auxiliary tasks (theme classification and tone prediction) will also improve the primary task (ideological classification) by capturing more comprehensive discourse patterns.

\subsection{Experimental Results}
\label{sec:continued-pretraining-results}

We employed the RoBERTa-base architecture \citep{liu2019roberta} as our foundation model, initializing from the standard pre-trained checkpoint before applying our continued pre-training regime for 2 epochs over the GDELT corpus. We also considered only the 2000 most frequent GDELT categories, and the triplet loss margin $\delta$ is set to 1. Specific pre-training settings can found in Table~\ref{tab:pretraining_config}.

We conducted experiments varying two key factors: the number of triplet samples per batch (1, 16, or 32) and the inclusion of metalinguistic objectives (theme prediction $T_h$, tone regression $T_o$, or both). Triplet generation followed the standard contrastive learning protocol: for each anchor article, we paired it with a positive example (same ideology label) and a negative example (different ideology label). During training, we randomly sampled the specified number of such triplets per batch from all valid combinations.

Following continued pre-training, we fine-tuned all models on the extended AllSides Media training split and evaluated on the test split. Each configuration was trained for two epochs, with Table~\ref{tab:pretraining-combined} reporting the best performance achieved across epochs.

\begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{@{}l|ccccc|ccccc@{}}
\toprule
\textbf{Experiment} & \multicolumn{5}{c|}{\textbf{Subset (1.6M, Complete GDELT)}} & \multicolumn{5}{c}{\textbf{Full (4.5M, 35\% GDELT)}} \\ 
\midrule
 & Ep. & F1 & L & C & R & Ep. & F1 & L & C & R \\
 \midrule
$T_{id}(1)$ & 2 & 50.12 & 69.28 & 18.09 & 63.00 & 2 & 56.98 & 73.82 & 33.96 & 63.55 \\
$T_{id}(1) + T_h$ & 1 & 52.02 & 71.61 & \textbf{33.41} & 51.03 & 2 & 51.40 & 68.17 & 21.81 & 64.21 \\
$T_{id}(1) + T_o$ & 2 & 53.39 & 71.65 & 28.31 & 60.20 & 2 & 55.86 & 72.46 & 31.17 & 63.93 \\
$T_{id}(1) + T_h + T_o$ & 2 & \textbf{56.56} & \textbf{72.58} & 30.39 & \textbf{66.71} & 2 & \textbf{60.78} & \textbf{73.05} & \textbf{39.48} & \textbf{69}.82 \\
\midrule
$T_{id}(16)$ & 2 & 50.06 & 72.07 & 20.53 & 57.59 & 2 & 52.88 & 68.36 & 22.02 & 68.26 \\
$T_{id}(16) + T_h$ & 2 & 50.10 & 67.33 & 16.23 & \textbf{66.74} & 1 & 60.55 & \textbf{74.11} & 38.22 & 69.31 \\
$T_{id}(16) + T_o$ & 2 & 53.30 & 71.99 & 22.08 & 65.83 & 2 & 53.76 & \textbf{74.11} & 19.71 & 67.45 \\
$T_{id}(16) + T_h + T_o$ & 2 & \textbf{56.56} & \textbf{72.58} & \textbf{30.39} & 66.71 & 2 & \textbf{60.78} & 73.05 & \textbf{39.48} & \textbf{69.82} \\
\midrule
$T_{id}(32)$ & 2 & 55.41 & 73.66 & 28.34 & 64.22 & 2 & 60.15 & 73.95 & 35.88 & 70.62 \\
$T_{id}(32) + T_h$ & 2 & 46.47 & 66.05 & 03.83 & 69.52 & 2 & \textbf{62.19} & \textbf{75.97} & \textbf{39.83} & \textbf{70.76} \\
$T_{id}(32) + T_o$ & 2 & 48.74 & 67.21 & 12.83 & 66.18 & 1 &  57.18 & 72.75 & 34.49 & 64.30 \\
$T_{id}(32) + T_h + T_o$ & 1 & \textbf{55.59} & \textbf{72.73} & 29.27 & \textbf{64.76} & 2 & 59.33 & 72.66 & \textbf{42.28} & 63.06 \\
\bottomrule
\end{tabular}
\caption{Continued Pre-training Results on both GDELT limited subset and full \textsc{BigNewsBLN} dataset.}
\label{tab:pretraining-combined}
\end{table}

Table~\ref{tab:pretraining-combined} presents results from pre-training on both the 1.6 million article subset with complete GDELT coverage, and the full 4.5 million article \textsc{BigNewsBLN} corpus, where metalinguistic objectives were applied only to the articles with available GDELT metadata. Our most effective configuration, $T_{32} + T_h$, achieved 62.19 F1-Macro on the full dataset, outperforming the POLITICS baseline (60.60) and demonstrating the value of combining intensive triplet training with theme prediction. The full results for each configuration across both epochs can be found in Appendix~\ref{sec:appendix-full-experiments}.

These findings extend prior work \citep{hamborg2019automatedmediabias,rashkin2016connotationframesdatadriveninvestigation} demonstrating the utility of metalinguistic cues such as sentiment and emotional tone in political ideology detection. Our results illustrate that explicitly incorporating such signals as auxiliary training objectives can yield substantial performance improvements for article-level political ideology classification. The best performing models (both \href{https://huggingface.co/dragonslayer631/roberta_metalinguistic_features_triplet_loss}{pre-trained checkpoints} and \href{https://huggingface.co/dragonslayer631/ideology_classifier_finetuned}{fine-tuned versions} on the extended AllSides dataset) are publicly available on HuggingFace.\footnote{Models available under the Apache 2.0 license.}

% TODO: Add error analysis to understand where the improved model still fails
% TODO: Add qualitative analysis of specific examples where metalinguistic features help
