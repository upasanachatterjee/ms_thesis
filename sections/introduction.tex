\section{Introduction}

The proliferation of politically biased content in news media poses significant challenges for public discourse, political polarization, and information integrity. Automatic detection of political bias in news articles represents an important research direction with applications in media literacy tools, content recommendation systems, and journalistic analysis. This paper addresses three interconnected questions in political ideology classification of U.S. news articles: (1) What level of performance can human annotators achieve when classifying ideology from text content alone, and how does this baseline inform our understanding of automated approaches? (2) How effectively can metalinguistic features such as article-level theme and tone be leveraged to improve transformer-based classification models? (3) How do modern large language models, both in zero-shot and fine-tuned settings, compare to specialized transformer architectures on this task?

Online media bias resources such as  or AdFontes\footnote{\url{https://adfontesmedia.com/}}, AllSides,\footnote{\url{https://www.allsides.com/unbiased-balanced-news}}, or MB/FC,\footnote{\url{https://mediabiasfactcheck.com/}} typically provide source-level rather than article-level bias ratings. Much of the previous work on news bias detection has similarly aimed at detecting bias at level of entire publications or authors \citep{baly2020acl, darwish2020aaai, ronnback2025biasoutlets}. Only AllSides additionally provides article-level ratings, and notably these ratings do not always align with source bias. \citet{baly2020we} used the article-level ratings to create the AllSides dataset, containing 34,737 articles with left, center, or right labels, which we use and extend in this paper.

Even though article level bias does not align with source level bias one-to-one, there is generally a strong correlation. \textit{Source leakage}, where classifiers learn specific patterns associated with the source (including identifiers such as author, style, explicit mentions) rather than content-based bias signals, is a crucial issue in article level bias detection. \citet{baly2020we} address this problem using triplet-loss pre-training for BERT, using contrastive learning to structure embeddings based on ideological similarity rather than source identifying patterns (see section \ref{sec:transformer-baselines}). \citet{liu2022politics} scaled the triplet-loss approach with a significantly larger pre-training dataset and refined the contrastive learning objectives to focus more specifically on same-story article comparisons across different sources. This resulted in the POLITICS model, which achieves current state of the art results on the AllSides dataset.

Recently, \citet{ronnback2025biasoutlets} demonstrated how semantic, syntactic, and metalinguistic features effectively capture source-level political bias 
We are the first to integrate metalinguistic features into an article-level bias classification system. Specifically, our approach extends triplet-loss pre-training approaches for transformer based classifiers to incorporate theme and tone prediction as auxiliary tasks, enabling the model to learn representations sensitive to both explicit content and implicit stylistic markers of political orientation.

We compare the performance of our pre-trained and fine-tuned classifier with general-purpose large language models, considering both zero-shot prompting and fine-tuned LLMs. Our experiments demonstrate that continued pre-trained/fine-tuned transformer classifiers demonstrate superior performance compared to both human baselines and general-purpose LLMs with zero-shot prompting on the source-separated Media-based split configuration of the AllSides dataset. We show that incorporating metalinguistic information as an auxiliary objective during pre-training yields additional performance improvements, particularly for challenging bias categories such as center-leaning content. 

Fine-tuned LLMs only approach performance of the transformer classifiers with substantial quantities of domain-specific training data. Prompt optimization methodologies yield marginal improvements.

The primary contributions of this paper are as follows:

\begin{itemize}
    \item We establish a new state-of-the-art for political bias classification of news articles via continued pre-training on RoBERTa using metalinguistic features.
    \item We perform the first evaluation of state-of-the-art language models on the political bias classification task.
    \item We introduce an expanded version of the AllSides dataset initially curated by \citet{baly2020we}, increasing the available annotated articles by 47\% over the original dataset. 
\end{itemize}

\section{Related Work}
Early approaches in automated ideology classification predominantly formulated the problem as binary classification or focused on identifying extreme partisan viewpoints (hyper-partisan news) \citep{hube2018detecting, semeval2019hyperpartisan, krieger2022daroberta, lin2024inditag}. The literature is also distinguished by granularity of analysis: while substantial research has focused on \textit{sentence-level} bias detection \citep{spinde2021mbic,spinde2021babe, menzner2025biasscanner}, identifying specific biased phrases or sentences, these approaches often fail to capture broader contextual or cumulative framing effects across entire articles. Article-level classification approaches, which we adopt in this work, consider the holistic political orientation of texts.

Recently, \citet{ronnback2025biasoutlets} demonstrated how semantic, syntactic, and metalinguistic features effectively capture source-level political bias, while \citet{recasens2013weasel} showed that similar stylistic features can identify potentially biased language in Wikipedia's NPOV corpus. This suggests that metalinguistic features may provide valuable complementary signals for ideology detection beyond content-based representations alone. However, prior work has not explored the integration of metalinguistic features into article-level political ideology classification systems.

The human ability to recognize and classify political ideology serves as an important reference point for automated systems. Previous studies have demonstrated the challenges inherent in such annotation tasks. The Media Bias Identification Corpus (MBIC) by \citet{spinde2021mbic} utilized crowdworkers to identify biased language, achieving only slight to fair inter-annotator agreement (Fleiss's Kappa $ \approx 0.21$). In response to these annotation challenges, the Bias Annotations by Experts (BABE) dataset relied on expert annotators specifically trained to recognize media bias, resulting in improved but still modest inter-annotator reliability (Krippendorff's Alpha $\approx 0.39$) \citep{spinde2021babe}.

These findings suggest that even expert human annotators face considerable challenges in consistently identifying biased content. Moreover, these prior studies primarily focused on  political bias detection rather than directional classification. In this work, we introduce an informal human baseline for political ideology prediction, to address the limited research involving human annotation that explicitly distinguishes direction (e.g., left-leaning versus right-leaning).
